{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOkgXDfC/Cog3qCJpbM/sjC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferchomuri/archi/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ðŸ“Œ Variables de entorno"
      ],
      "metadata": {
        "id": "_JDN5WpMbcYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "LqJIe_CtadkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Instalar librerÃ­as necesarias"
      ],
      "metadata": {
        "id": "Ti0qWL7QbAgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets accelerate huggingface_hub safetensors\n",
        "!pip install bitsandbytes transformers accelerate\n"
      ],
      "metadata": {
        "id": "PqjpL5hNa6Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
        "from huggingface_hub import login\n",
        "from datasets import load_dataset\n",
        "from accelerate import infer_auto_device_map\n",
        "from transformers import BitsAndBytesConfig\n",
        "from safetensors.torch import save_file, load_file"
      ],
      "metadata": {
        "id": "QppEDVxWbFQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fOAkWb6bOqKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Iniciar sesiÃ³n en Hugging Face (sustituye tu token)*italicized text*"
      ],
      "metadata": {
        "id": "gpsr-egDbJ-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HUGGINGFACE_TOKEN = userdata.get('hugface')\n",
        "login(HUGGINGFACE_TOKEN)"
      ],
      "metadata": {
        "id": "HwQTKLwHbKV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Modelo base"
      ],
      "metadata": {
        "id": "lwN7D6DLbXL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"microsoft/graphcodebert-base\""
      ],
      "metadata": {
        "id": "jSi4xV6BbYET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Configurar el modelo con 8-bit quantization para reducir uso de memoria\n"
      ],
      "metadata": {
        "id": "c0CU2Hu0kFGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bnb_config = BitsAndBytesConfig(load_in_8bit=True)  # Activa carga en 8 bits\n"
      ],
      "metadata": {
        "id": "O_JeU4xxj_10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Cargar el modelo optimizado para menor consumo de memoria"
      ],
      "metadata": {
        "id": "w921JIIzbZEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    # torch_dtype=torch.float16,\n",
        "    device_map=\"cpu\"\n",
        ")"
      ],
      "metadata": {
        "id": "8VaFIhEHbaca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Cargar el tokenizador"
      ],
      "metadata": {
        "id": "9b-TwPEwbxjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "IFk2Ssl6bz37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Configurar token de padding si no existe"
      ],
      "metadata": {
        "id": "WQsZ8dsqb2uM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\"Modelo cargado correctamente âœ…\")"
      ],
      "metadata": {
        "id": "5CL3psB_b5gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Subir archivos JSONL al entorno de Colab (solo la primera vez)"
      ],
      "metadata": {
        "id": "JN1sxR1Ab9Rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Selecciona tus archivos JSONL cuando aparezca la ventana\n"
      ],
      "metadata": {
        "id": "FC1o7eNxb_cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Cargar dataset local"
      ],
      "metadata": {
        "id": "kmXotlBucDoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"json\", data_files=list(uploaded.keys()))\n",
        "\n",
        "print(\"Dataset cargado correctamente âœ…\")"
      ],
      "metadata": {
        "id": "-jYaL2prcFm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ FunciÃ³n para tokenizar el dataset"
      ],
      "metadata": {
        "id": "wVMgw3smcGoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"prompt\"],\n",
        "        text_target=examples[\"completion\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=256\n",
        "    )"
      ],
      "metadata": {
        "id": "fXeOmOHbcJoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Tokenizar dataset"
      ],
      "metadata": {
        "id": "-1xDnTlPcKiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"Dataset tokenizado correctamente âœ…\")"
      ],
      "metadata": {
        "id": "DtC5qSvUcLdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Dividir el dataset en train (80%) y eval (20%)"
      ],
      "metadata": {
        "id": "22RYPgo5cPjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset = tokenized_datasets[\"train\"].train_test_split(test_size=0.2)\n"
      ],
      "metadata": {
        "id": "IltTG-uCcRGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Configurar los argumentos de entrenamiento"
      ],
      "metadata": {
        "id": "J1Qr6IFLcSE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    push_to_hub=False,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=8,\n",
        "    gradient_checkpointing=True\n",
        ")"
      ],
      "metadata": {
        "id": "PV4tNNkncUwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Inicializar Trainer"
      ],
      "metadata": {
        "id": "vmnVf8i3cV4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=split_dataset[\"train\"],\n",
        "    eval_dataset=split_dataset[\"test\"]\n",
        ")"
      ],
      "metadata": {
        "id": "1b4ii20acYDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ Iniciar entrenamiento"
      ],
      "metadata": {
        "id": "9Yb-IGLacZCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "8IK9nvf-cb5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}